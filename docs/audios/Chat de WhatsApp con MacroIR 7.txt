10/11/25, 14:10 - Los mensajes y las llamadas están cifrados de extremo a extremo. Solo las personas en este chat pueden leerlos, escucharlos o compartirlos. Obtén más información.
10/11/25, 14:10 - Creaste este grupo
10/11/25, 14:11 - Luciano Moffatt: <Multimedia omitido>
10/11/25, 14:14 - Luciano Moffatt: <Multimedia omitido>
10/11/25, 14:20 - Luciano Moffatt: <Multimedia omitido>
10/11/25, 14:29 - Luciano Moffatt: <Multimedia omitido>
10/11/25, 14:32 - Luciano Moffatt: <Multimedia omitido>
10/11/25, 14:47 - Luciano Moffatt: <Multimedia omitido>
10/11/25, 14:59 - Luciano Moffatt: _Bueno, llegamos a un punto final de ir cerrando lo que serían las figuras del paper y la narrativa del paper. Entonces la narrativa consiste en ver qué es lo que queremos decir. Bueno, ahí vamos a hablar un poco en principio. Bueno, queremos presentar Macro y R. ¿Qué es lo que resolvemos? ¿Qué es lo que me gustaría que la gente entienda de eso? Bueno, primero que digamos lo concreto, ¿no? Que resuelve el problema de expresar con..._

 -- Transcrito por zapia.com, tu IA personal
10/11/25, 14:59 - Luciano Moffatt: _Lo más importante, lo más práctico de MacroIR es que, bueno, permite, digamos, calcular con precisión la likelihood de modelos marcovianos en el caso de macrocorrientes de canales iónicos que tienen integración temporal, es decir, que son registros integrados en el tiempo, lo cual es en principio cualquier registro va a ser integrado en el tiempo, y que además esto, digamos, sería válido no solamente para canales iónicos, sino que sería fácilmente extendible a cualquier proceso biológico o no biológico, digamos, que pueda ser simulado con procesos marcovianos. Es decir, es un algoritmo que permite calcular la likelihood de un proceso donde se observan, digamos, donde la observación es promediada en el tiempo del sistema marcoviano. Que, digamos, en principio cualquier observación va a ser promediada en el tiempo porque no existe una observación instantánea. físicamente es imposible._

 -- Transcrito por zapia.com, tu IA personal
10/11/25, 14:59 - Luciano Moffatt: _Bueno, entonces ahora viene el punto de las figuras. Entonces la primera figura claramente tiene que ser una figura que yo me la imagino mostrando el macro R y macro IR como alternativamente. Macro R siendo un modelo puntual y Macro R un modelo de intervalos. Y ese, no sé, esa es la primera figura mostrando un esquema de cómo funciona el algoritmo. Y yo lo imagino, digamos, con flechitas, no sé, simbolitos. O sea, eso tengo que hacer un ideograma bien claro de eso. esa es digamos el punto 1 el punto 2 es bueno ¿qué esquema trato de analizar? entonces ¿qué esquemas podrían realizar? podrían realizar un esquema de 3 estados por ejemplo como el mínimo luego ir con el esquema 1, 2 y 1, 2, 3 y 4 por ejemplo, o sea que serían esos cinco esquemas y en todos probar la, o podría probar en todos los esquemas que yo trabaja en el paper, o sea, quien prueba uno puede probar ocho, no sé, o nueve, no me acuerdo cuántos eran, creo que eran 8, que provenen de Communications Biology. Sin la, o sea, lo que no estaría poniendo es la Confusion Matrix, ¿no? O sea, solamente presento las informaciones del film y todo eso. claro, lo que tendría que hacer hay que cuáles son mis mis algoritmos que voy a probar bueno tengo que probar macro R macro NR macro IR y macro INR macro INR creo que es, sí. Y habría que ver también el macro AR o algo así que sería como Average en el cual, digamos, sería equivalente al método de de Munch pero también podría ser que el método de Munch también tiene la corrección de Taylor de la varianza entonces ahí sería uno más y podría ser la corrección de Taylor de la varianza del mío también entonces ahí todo se llevaría a una matriz de ¿cuánto sería? a ver tendríamos cosa tendrías IR IVR ¿no? AVR y AR, algo así serían dos más, o sea, agregaría entonces tenemos macro R y macro NR son los dos iniciales Después le sumo macro IR, macro INR, dos más. Y claro, tengo que sumarle ahora el macro AR. Y el macro IVR y el macro AVR. O sea que serían tres más. O sea, de los cuales serían siete modelos en total. ¿No es cierto? A ver. Son. Sí. Son, claro, macro R y... Sí. Exactamente. Y podría ser, claro... Podría meter dos más, nueve algoritmos, algo así. De ver cu ser los que andan Eso es un poco demasiado confuso quiz pero bueno podr probarlo y ver qué es lo que da y bueno, ver las condiciones de claro, y eso tendría que probar con distintos números en función de qué qué es lo que va a fallar uno u otro bueno Bueno, la corriente esperada y... A ver, ¿cómo sería el número de canales? Las cosas que puedo cambiar son... Bueno, primero sí, la corriente esperada, el número de canales y lo que sería el intervalo de tiempo comparado con la constante, con una constante de tiempo del canal, ¿no? Que sería por ahí posiblemente la más rápida o la, no sé cuál sería, habría que ver bien exactamente. Pero bueno, sí, sería digamos en función de la constante de tiempo, ¿no? O sea que vos tendrías, claro, que ahí yo lo que tenía eso, integration time, mira lo que tomaba como variable para ver en qué condiciones cada uno de los algoritmos funciona. O sea que la idea de la paper es ver exactamente en qué regiones el algoritmo funciona, y distintos algoritmos funcionan en distintas regiones. Algo así sería. y donde fallan completamente y donde claro, te pueden dar valores que no que no andan o sea que te den un este, sí un valor no sabes por ejemplo que es que la sí, que te den un valor no devaluen, ¿no? porque puede ser una raíz cuadrada en un número negativo o algo así entonces claro ver eso y verlo eso en funci de c explicar en qu regiones el algoritmo funciona O sea en realidad digamos a ver claro a ver pensemoslo bien O sea, el paper es presentar algoritmos y presentar en qué condiciones el algoritmo está en la zona de función. Básicamente ese es el objetivo y entonces por eso está bien, la unidad es una medición sí, exactamente el objetivo es una medición porque vos querés ver en qué condiciones extremas, digamos el aerobismo funciona y no funciona y estudiar eso bien a fondo o sea, que ese..._
10/11/25, 14:59 - Luciano Moffatt: _sería un poco lo que sería la carne también del taper O sea, no solamente que el algoritmo funciona, sino dónde funciona. Ahí está, ahí está el asunto. Ese es el tercer punto, no, el cuarto punto, porque tenemos el primer punto es, bueno, presentar el algoritmo, el problema y la solución. El segundo es cuál es la naturaleza de la solución, digamos, usamos la genialidad de esa solución. El tercero es cómo estoy probando que el algoritmo está funcionando. Y cuarto es en qué condiciones el algoritmo funciona. Y justamente la teoría detrás, digamos, porque yo tengo ciertas aproximaciones detrás del algoritmo, entonces ver un poco cómo puedo aproximar en qué condiciones el algoritmo, o sea, por qué el algoritmo reventaría en algunas circunstancias. Y eso ya es un poco más difícil, la teoría de por qué la aproximación falla. O sea, exactamente, tendría que hacer claro una teoría de la aproximación del algoritmo. O sea, exactamente, eso está bien._
 -- Transcrito por zapia.com, tu IA personal
10/11/25, 14:59 - Luciano Moffatt: _El segundo punto es, digamos, cuál fue la estrategia para lograr esto. Y bueno, ahí está un detalle, ¿no? O sea, ¿a quién le importa la estrategia para lograr esto? O sea, en realidad, digamos, la estrategia fue tomar un modelo equivalente, equivalente, o sea, transformar el problema de infinitas trayectorias en el tiempo en un sistema que te permita, digamos, predecir, te permita sintetizar la información que vos necesitas saber para poder predecir todos los posibles caminos en el tiempo. Y este es el estado inicial y el estado final. O sea, vos conociendo un estado, el estado inicial, al comenzar el intervalo y el estado final, vos podés predecir la esperanza de las trayectorias de los observables y también la varianza de la esperanza del promedio de las observaciones observadas, las observaciones del sistema del proceso Markoviano en ese intervalo. Entonces digamos la idea de que digamos o sea volvemos a tener un sistema marcoviano porque teniendo dos sistemas instant uno inicial y otro final podemos, matamos dos pájanas de un tiro, o sea, podemos calcular las trayectorias promedio, dado un estado inicial y un estado final, Y tenemos la información que nos interesa para hacer las trayectorias futuras, que es el estado final del sistema. O sea, eso del punto de vista conceptual, yo creo que es interesante, pero claro, no es... O sea, ¿por qué podría ser central decir, digamos, esta estrategia para resolver el problema? Bueno, si lo podés aplicar la misma estrategia para otros problemas, ahí tendría sentido presentarla como un resultado en sí mismo. Pero en principio no se me ocurren otras posibilidades, entonces para mí quedaría un poco a segundo plano. O sea, el primer plano es que se resuelve el problema y que entonces tenemos disponible esta posibilidad. después bueno, que es una estrategia que quizás pueda ser usado en otros casos, que la verdad que no sé cuáles serían pero bueno, puede ser puede dar lugar a inspiraci para solucionar problemas similares o lo que sea bueno ese es el segundo punto del macro IR Y el tercer punto es el hecho de que para poder comparar la likelihood digamos lo normal es correr un Monte Carlo Markov Chain y ver que realmente vos recuperas los parámetros iniciales que vos buscabas. Pero bueno, yo lo que planteo es un shortcut, un atajo, que consiste en tomar como un test estadístico inmediato, el tomar la expectativa del gradiente de la log likelihood, o sea la expectativa del score que ya debería ser cero y tomar digamos la como una un test donde tomamos la varianza del score digamos si hacemos un test de la likelihood o digamos tomó la Fisher Information Matrix. Bueno, eso está, digamos, descrito en algunas versiones anteriores de Labs, Red y qué sé yo. Entonces, claro, me queda la pregunta, ¿será suficiente con eso? o si adem deber mostrar que eso implica que recupere los valores verdaderos de los par Bueno el hecho mismo de que el gradiente sea cero te indicaría que lo estaría recuperando. Lo que podría pasar es que haya otros puntos donde el gradiente también sea cero, que sean distintos de este. Pero bueno, sí, no sé. Eso podría hacer que sea bueno hacer un test adicional, mostrando que además se recupera el valor de los parámetros del modelo proporcionados. Pero bueno, no sé, eso me metería el tema de meter un Monte Carlo Markov Chain y todo eso, que en realidad, digamos, lo que puedo decir es referirlo, eso ya lo hice en Communication Biology, mostré que se recuperaba todo, digamos, podría referirlo ahí. y que después en un trabajo extra mostraré cómo estudiar bien la parte del Monte Carlo Marco Chain sobre esta Doc Lightly Hood, o sea, caracterizarla mejor, digamos, como un otro trabajo adicional. Yo iría por ese lado y listo, porque si no queda muy cargado, está bien, me como eso que dije al principio, Entonces está bien, separo._

 -- Transcrito por zapia.com, tu IA personal
10/11/25, 14:59 - Luciano Moffatt: _Entonces para ver esos problemas cuando falla, claro, ¿qué parámetros son importantes? ¿Qué parámetros se determinan? Bueno, dijimos que vos los tenés. Tenés por un lado el parámetro número uno, es el número de canales, ¿cierto? Después es la relación ruido, señala ruido, entre la corriente de un canal y el ruido. El factor 3 es la constante de tiempo de la apertura del canal. el factor 4 es, claro, qué probabilidad hay, no sé cuántos, o sea, qué en efectivo estaríamos trabajando, o sea, o qué número de aperturas quizás sea, número de eventos aleatorios quizás, es un poco la idea, ¿no? y este claro b el n de eventos aleatorios estamos trabajando si eres muy pocos entonces claramente la instituci estar fallar Y claro y despu tenemos la complejidad del n de estados eso quiz me complique la existencia y lo más fácil sea, sí, pensar en dos estados o en tres, o sea, primero Podríamos pensar en dos estados porque al pensar en dos estados es como más fácil establecer todos estos límites de manera super clara. Eso me queda super claro. Y entonces vos le vas metiendo más estados y ves cómo eso te cambia el panorama. Está bien. Porque acá lo importante es entender, digamos, y fundamentalmente entender en qué condiciones el algoritmo funciona O sea, exactamente, o sea, la idea es, bueno, qué algoritmo es y en qué condiciones es simple O sea, es un martillo que golpea los clavos de tal tamaño a tal otro y no en otras circunstancias Si en todas circunstancias harán falta otras herramientas. Sí. Está bien._

 -- Transcrito por zapia.com, tu IA personal
10/11/25, 14:59 - Luciano Moffatt: _Bueno, finalmente me doy cuenta que si hago dos estados nada más, en realidad el método ideal es un micro IR, porque es barato, digamos, con el número de estados igual al número de canales más uno, No hay ninguna razón para no aplicar este método directamente. Lo cual complicaría un poco las cosas porque tendría que desarrollar la teoría de micro R, micro NR. Entonces la pregunta es si vale la pena o no. lo bueno es que con micro R tendría digamos un gold standard de lo que es la likelihood lo que me quedar es el tema de que yo digo estoy estimando la como normal, estoy modelando la conductancia o la observancia media como normal, siendo una institución normal cuando sabemos que eso no es así, pero bueno, si vos tenés muchos canales, bueno, eso lo podés tranquilamente suponer. O sea, ahí digamos lo único que no funcionaría es para canal único, ahí no, estás en el horno y tendríamos que usar una distribución más apropiada, digamos que no sería la distribución normal pero si así tenés 4 o 5 canales ya no hay ningún problema con la distribución normal en principio esa sería un poco la idea bueno entonces la pregunta es si vale la pena poner micro R y micro IR_

 -- Transcrito por zapia.com, tu IA personal
